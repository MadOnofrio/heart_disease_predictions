set.seed(123)
lda_clf = train(TenYearCHD ~., data = x_train, method="lda", trControl=control)
lda_clf
set.seed(7)
svm_clf = train(TenYearCHD ~., data = x_train, method = "svmPoly", trControl = control)
svm_clf
set.seed(123)
forest_clf = train(TenYearCHD ~., data = x_train, method = "rf",
trControl = control)
forest_clf
set.seed(123)
xgb_grid_1  <-  expand.grid(
nrounds = 50,
eta = c(0.03),
max_depth = 1,
gamma = 0,
colsample_bytree = 0.6,
min_child_weight = 1,
subsample = 0.5
)
xgb_clf = train(TenYearCHD ~., data = x_train,
method = "xgbTree",
tuneGrid=xgb_grid_1,
trControl = control
)
xgb_clf
set.seed(123)
knn_clf = train(TenYearCHD ~., data = x_train,
method = "knn",
tuneGrid = expand.grid(.k = c(3:10)),
trControl = control,
)
knn_clf
results = resamples(list(LOGREG=glm_clf, LDA=lda_clf, SVM=svm_clf, KNN=knn_clf, RF=forest_clf, XGB = xgb_clf))
summary(results)
scales = list(x=list(relation="free"), y=list(relation="free"))
bwplot(results, scales=scales)
par(mfrow = c(200,200))
splom(results)
xyplot(results, models=c("RF", "LOGREG"))
glm_predictions = predict(glm_clf, x_test)
lda_predictions = predict(lda_clf, x_test)
svm_predictions = predict(svm_clf, x_test)
knn_predictions = predict(knn_clf, x_test)
forest_predictions = predict(forest_clf, x_test)
xgb_predictions = predict(xgb_clf, x_test)
glm_scores = predict(glm_clf, x_test, type = "prob")
lda_scores = predict(lda_clf, x_test, type = "prob")
#svm_scores = predict(svm_clf, x_test, type = "prob")
knn_scores = predict(knn_clf, x_test, type = "prob")
forest_scores = predict(forest_clf, x_test, type = "prob")
xgb_scores = predict(xgb_clf, x_test, type = "prob")
cm_glm = confusionMatrix(data = glm_predictions, reference = x_test$TenYearCHD, positive = "1")
cm_glm
pred_roc_glm = prediction(glm_scores[,2], x_test$TenYearCHD)
glm_ROCR = performance(pred_roc_glm, measure = "tpr", x.measure = "fpr")
par(mfrow=c(1,1))
plot(glm_ROCR, main = "ROC curve for Logistic Reg.", colorize = T, xlab="False Positive rate", ylab="True Positive rate" )
abline(a = 0, b = 1)
auc_glm = performance(pred_roc_glm, measure = "auc")
auc_glm = auc_glm@y.values[[1]]
auc_glm
cm_lda = confusionMatrix(data = lda_predictions, reference = x_test$TenYearCHD, positive = "1")
cm_lda
pred_roc_lda = prediction(lda_scores[,2], x_test$TenYearCHD)
lda_ROCR = performance(pred_roc_lda, measure = "tpr", x.measure = "fpr")
par(mfrow=c(1,1))
plot(lda_ROCR, main = "ROC curve for LDA", colorize = T, xlab="False Positive rate", ylab="True Positive rate" )
abline(a = 0, b = 1)
auc_lda = performance(pred_roc_lda, measure = "auc")
auc_lda = auc_lda@y.values[[1]]
auc_lda
cm_svm = confusionMatrix(data = svm_predictions, reference = x_test$TenYearCHD, positive = "1")
cm_svm
cm_knn = confusionMatrix(data = knn_predictions, reference = x_test$TenYearCHD, positive = "1")
cm_knn
pred_roc_knn = prediction(knn_scores[,2], x_test$TenYearCHD)
knn_ROCR = performance(pred_roc_knn, measure = "tpr", x.measure = "fpr")
par(mfrow=c(1,1))
plot(knn_ROCR, main = "ROC curve for KNN", colorize = T, xlab="False Positive rate", ylab="True Positive rate" )
abline(a = 0, b = 1)
auc_knn = performance(pred_roc_knn, measure = "auc")
auc_knn = auc_knn@y.values[[1]]
auc_knn
cm_forest = confusionMatrix(data = forest_predictions, reference = x_test$TenYearCHD, positive = "1")
cm_forest
pred_roc_forest = prediction(forest_scores[,2], x_test$TenYearCHD)
forest_ROCR = performance(pred_roc_forest, measure = "tpr", x.measure = "fpr")
par(mfrow=c(1,1))
plot(forest_ROCR, main = "ROC curve for Random forest", colorize = T, xlab="False Positive rate", ylab="True Positive rate" )
abline(a = 0, b = 1)
auc_forest = performance(pred_roc_forest, measure = "auc")
auc_forest = auc_forest@y.values[[1]]
auc_forest
cm_xgb = confusionMatrix(data = xgb_predictions, reference = x_test$TenYearCHD, positive = "1")
cm_xgb
pred_roc_xgb = prediction(xgb_scores[,2], x_test$TenYearCHD)
xgb_ROCR = performance(pred_roc_xgb, measure = "tpr", x.measure = "fpr")
par(mfrow=c(1,1))
plot(xgb_ROCR, main = "ROC curve for XGB", colorize = T, xlab="False Positive rate", ylab="True Positive rate" )
abline(a = 0, b = 1)
auc_xgb = performance(pred_roc_xgb, measure = "auc")
auc_xgb = auc_xgb@y.values[[1]]
auc_xgb
ModelType = c( "LOGREG", "LDA", "SVM", "KNN", "Random forest", "XGB")
TrainAcc = c(max(glm_clf$results$Accuracy), max(lda_clf$results$Accuracy),
max(svm_clf$results$Accuracy), max(knn_clf$results$Accuracy),
max(forest_clf$results$Accuracy),
max(xgb_clf$results$Accuracy))
Train_misscl_Er = 1 - TrainAcc
ValidAcc = c(cm_glm$overall[1], cm_lda$overall[1], cm_svm$overall[1],
cm_knn$overall[1], cm_forest$overall[1],
cm_xgb$overall[1])
Valid_misscl_Er = 1 - ValidAcc
auc_svm = NA
auc_scores = c(auc_glm, auc_lda, auc_svm, auc_knn, auc_forest, auc_xgb)
metrics = cbind(ModelType, TrainAcc, Train_misscl_Er, ValidAcc,
Valid_misscl_Er, auc_scores)
metrics = data.frame(metrics)
knitr::kable(metrics, digits = 3)
model_compare = cbind(Model=ModelType, Accuracy=TrainAcc)
model_compare = data.frame(model_compare)
ggplot(aes(x=Model, y=Accuracy), data=model_compare) +
geom_bar(stat='identity', fill = 'blue') +
ggtitle('Comparative Accuracy of Models on Cross-Validation Training Data') +
xlab('Models') +
ylab('Overall Accuracy')
model_compare = cbind(Model=ModelType, Accuracy=ValidAcc)
model_compare = data.frame(model_compare)
ggplot(aes(x=Model, y=Accuracy), data=model_compare) +
geom_bar(stat='identity', fill = 'orange') +
ggtitle('Comparative Accuracy of Models on Cross-Validation Test Data') +
xlab('Models') +
ylab('Overall Accuracy')
dim(y_test)
dim(x_test)
table(x_test$TenYearCHD)
precision(lda_predictions, x_test$TenYearCHD)
lda_predictions
recall(lda_predictions, x_test$TenYearCHD)
precision(data = lda_predictions, reference = x_test$TenYearCHD)
recasll(data = lda_predictions, reference = x_test$TenYearCHD)
recall(data = lda_predictions, reference = x_test$TenYearCHD)
library(skimr)
library(dplyr)
library(caret)
library(corrplot)
library(ROCR)
library(MASS)
library(psych)
library(ggplot2)
library(klaR)
library(tidyr)
library(cowplot)
library(mlbench)
library(AppliedPredictiveModeling)
library(car)
library(rattle)
library(e1071)
library(kernlab)
library(ROSE)
recall(data = lda_predictions, reference = x_test$TenYearCHD)
recall(data = lda_predictions, reference = x_test$TenYearCHD)
recall(lda_predictions, x_test$TenYearCHD, levels(x_test$TenYearCHD)[2])
recall(lda_predictions, x_test$TenYearCHD)
128/(128+42)
128/(128/236)
128/(128+236)
128/(128+234)
128/(128+44)
84/(84+44)
84/(84+234)
svm_radial = svm(TenYearCHD~., data = x_train, kernel = "radial")
svm_radial_predictions = predict(svm_radial, x_test)
confusionMatrix(svm_radial_predictions, x_test$TenYearCHD, positive = "1")
set.seed(7)
tune_svm = tune(svm, TenYearCHD ~., data=x_train, kernel='linear',
ranges=list(cost=c(0.001,0.01,0.1,1,5,10,100)))
summary(tune_svm)
set.seed(7)
svm_clf = train(TenYearCHD ~., data = x_train, method = "svmLinear", trControl = control)
svm_clf
results = resamples(list(LOGREG=glm_clf, LDA=lda_clf, SVM=svm_clf, KNN=knn_clf, RF=forest_clf, XGB = xgb_clf))
summary(results)
scales = list(x=list(relation="free"), y=list(relation="free"))
bwplot(results, scales=scales)
glm_predictions = predict(glm_clf, x_test)
lda_predictions = predict(lda_clf, x_test)
svm_predictions = predict(svm_clf, x_test)
knn_predictions = predict(knn_clf, x_test)
forest_predictions = predict(forest_clf, x_test)
xgb_predictions = predict(xgb_clf, x_test)
glm_scores = predict(glm_clf, x_test, type = "prob")
lda_scores = predict(lda_clf, x_test, type = "prob")
#svm_scores = predict(svm_clf, x_test, type = "prob")
knn_scores = predict(knn_clf, x_test, type = "prob")
forest_scores = predict(forest_clf, x_test, type = "prob")
xgb_scores = predict(xgb_clf, x_test, type = "prob")
cm_glm = confusionMatrix(data = glm_predictions, reference = x_test$TenYearCHD, positive = "1")
cm_glm
pred_roc_glm = prediction(glm_scores[,2], x_test$TenYearCHD)
glm_ROCR = performance(pred_roc_glm, measure = "tpr", x.measure = "fpr")
par(mfrow=c(1,1))
plot(glm_ROCR, main = "ROC curve for Logistic Reg.", colorize = T, xlab="False Positive rate", ylab="True Positive rate" )
abline(a = 0, b = 1)
auc_glm = performance(pred_roc_glm, measure = "auc")
auc_glm = auc_glm@y.values[[1]]
auc_glm
cm_lda = confusionMatrix(data = lda_predictions, reference = x_test$TenYearCHD, positive = "1")
cm_lda
pred_roc_lda = prediction(lda_scores[,2], x_test$TenYearCHD)
lda_ROCR = performance(pred_roc_lda, measure = "tpr", x.measure = "fpr")
par(mfrow=c(1,1))
plot(lda_ROCR, main = "ROC curve for LDA", colorize = T, xlab="False Positive rate", ylab="True Positive rate" )
abline(a = 0, b = 1)
auc_lda = performance(pred_roc_lda, measure = "auc")
auc_lda = auc_lda@y.values[[1]]
auc_lda
cm_svm = confusionMatrix(data = svm_predictions, reference = x_test$TenYearCHD, positive = "1")
cm_svm
ModelType = c( "LOGREG", "LDA", "SVM", "KNN", "Random forest", "XGB")
TrainAcc = c(max(glm_clf$results$Accuracy), max(lda_clf$results$Accuracy),
max(svm_clf$results$Accuracy), max(knn_clf$results$Accuracy),
max(forest_clf$results$Accuracy),
max(xgb_clf$results$Accuracy))
Train_misscl_Er = 1 - TrainAcc
ValidAcc = c(cm_glm$overall[1], cm_lda$overall[1], cm_svm$overall[1],
cm_knn$overall[1], cm_forest$overall[1],
cm_xgb$overall[1])
Valid_misscl_Er = 1 - ValidAcc
auc_svm = NA
auc_scores = c(auc_glm, auc_lda, auc_svm, auc_knn, auc_forest, auc_xgb)
metrics = cbind(ModelType, TrainAcc, Train_misscl_Er, ValidAcc,
Valid_misscl_Er, auc_scores)
metrics = data.frame(metrics)
knitr::kable(metrics, digits = 3)
model_compare = cbind(Model=ModelType, Accuracy=TrainAcc)
model_compare = data.frame(model_compare)
ggplot(aes(x=Model, y=Accuracy), data=model_compare) +
geom_bar(stat='identity', fill = 'blue') +
ggtitle('Comparative Accuracy of Models on Cross-Validation Training Data') +
xlab('Models') +
ylab('Overall Accuracy')
model_compare = cbind(Model=ModelType, Accuracy=ValidAcc)
model_compare = data.frame(model_compare)
ggplot(aes(x=Model, y=Accuracy), data=model_compare) +
geom_bar(stat='identity', fill = 'orange') +
ggtitle('Comparative Accuracy of Models on Cross-Validation Test Data') +
xlab('Models') +
ylab('Overall Accuracy')
gc()
645/4238
model.matrix(~0+., data = df) %>%
#cor(use="pairwise.complete.obs") %>%
corrplot(method = "color", type = "upper",number.cex = .5, order="hclust", addCoef.col = "black",tl.col = "#CC9900",            diag=F)
model.matrix(~0+., data = df) %>%
cor(use="pairwise.complete.obs") %>%
corrplot(method = "color", type = "upper",number.cex = .5, order="hclust", addCoef.col = "black",tl.col = "#CC9900",            diag=F)
lda_cv  = lda(TenYearCHD~., data = x_test, CV = TRUE)
confusionMatrix(data = lda_cv$class, reference = x_test$TenYearCHD, positive = "1")
pred_roc = prediction(lda_cv$posterior[,"1"], x_test$TenYearCHD)
roc_ROCR = performance(pred_roc, measure = "tpr", x.measure = "fpr")
par(mfrow=c(1,1))
plot(roc_ROCR, main = "ROC curve", colorize = T, xlab="False Positive rate", ylab="True Positive rate" )
abline(a = 0, b = 1)
auc_ROCR <- performance(pred_roc, measure = "auc")
auc_ROCR <- auc_ROCR@y.values[[1]]
auc_ROCR
lda_clf = lda(TenYearCHD ~., data = x_train)
lda_clf
plot(lda_clf)
lda_predictions = predict(lda_clf, x_test)
names(lda_predictions)
mean(lda_predictions$class==x_test$TenYearCHD)
lda_cv  = lda(TenYearCHD~., data = x_test, CV = TRUE)
confusionMatrix(data = lda_cv$class, reference = x_test$TenYearCHD, positive = "1")
control <- trainControl(method="repeatedcv", number=10, repeats=3)
knitr::opts_chunk$set(echo = TRUE)
rm(list=ls())
library(skimr)
library(dplyr)
library(caret)
library(corrplot)
library(ROCR)
library(MASS)
library(psych)
library(ggplot2)
library(klaR)
library(tidyr)
library(cowplot)
library(mlbench)
library(AppliedPredictiveModeling)
library(car)
library(rattle)
library(e1071)
library(kernlab)
library(ROSE)
df = read.csv("framingham.csv", header = T)
attach(df)
head(df)
str(df)
skim(df)
sum(is.na(df))
par(mfrow=c(3,3), mar=c(4,4,2,0.5))
for (j in 1:ncol(df[c(3,5,6,10,13,14,15)])) {
hist(df[c(3,5,6,10,13,14,15)][,j], xlab=colnames(df[c(3,5,6,10,13,14,15)])[j],
main=paste("Histogram of", colnames(df[c(3,5,6,10,13,14,15)])[j]),
col="lightblue", breaks=20)
}
summary(df[c(3,5,6,10,13,14,15)])
df =df %>%
replace_na(list(education = 1, cigsPerDay = 0, BPMeds = 0, totChol = 234,
BMI = 25.40, heartRate = 75, glucose = 78))
df$male <- factor(df$male)
df$education <- factor(df$education)
df$currentSmoker <- factor(df$currentSmoker)
df$BPMeds <- factor(df$BPMeds)
df$prevalentStroke <- factor(df$prevalentStroke)
df$prevalentHyp <- factor(df$prevalentHyp)
df$diabetes <- factor(df$diabetes)
df$TenYearCHD <- factor(df$TenYearCHD)
df$education <- factor(df$education)
str(df)
skim(df)
x <- ggplot(data = df, mapping = aes(x = TenYearCHD, y = age, fill = TenYearCHD)) +
geom_boxplot()
y <- ggplot(data = df, mapping = aes(x = as.factor(TenYearCHD), y = totChol, color = TenYearCHD)) +
geom_boxplot()
p <- cowplot::plot_grid(x, y)
title <- cowplot::ggdraw() + cowplot::draw_label("1. Relationship between TenYearCHD and Age / TotCHOL", fontface='bold')
cowplot::plot_grid(title, p, ncol=1, rel_heights=c(0.1, 1))
x <- ggplot(data = df, mapping = aes(x = TenYearCHD, y = sysBP, fill = TenYearCHD)) +
geom_boxplot()
y <- ggplot(data = df, mapping = aes(x = TenYearCHD, y = diaBP, color = TenYearCHD)) +
geom_boxplot()
p <- plot_grid(x, y)
title <- ggdraw() + draw_label("2. Relationship between TenYearCHD and sysBP / diaBP", fontface='bold')
plot_grid(title, p, ncol=1, rel_heights=c(0.1, 1))
x <- ggplot(data = df, mapping = aes(x = TenYearCHD, y = BMI, fill = TenYearCHD)) +
geom_boxplot()
y <- ggplot(data = df, mapping = aes(x = TenYearCHD, y = heartRate, color = TenYearCHD)) +
geom_boxplot()
p <- plot_grid(x, y)
title <- ggdraw() + draw_label("3. Relationship between TenYearCHD and BMI / HeartRate", fontface='bold')
plot_grid(title, p, ncol=1, rel_heights=c(0.1, 1))
x <- ggplot(data = df, mapping = aes(x = TenYearCHD, y = glucose, fill = TenYearCHD)) +
geom_boxplot()
y <- ggplot(data = df, mapping = aes(x = TenYearCHD, y = cigsPerDay, fill = TenYearCHD)) +
geom_boxplot()
p <- plot_grid(x,y)
title <- ggdraw() + draw_label("4. Relationship between TenYearCHD and Glucose / Cigs per Day", fontface='bold')
plot_grid(title, p, ncol=1, rel_heights=c(0.1, 1))
x <- ggplot(data = df) +
geom_count(mapping = aes(x = male, y = TenYearCHD))
y <- ggplot(data = df) +
geom_count(mapping = aes(x = diabetes, y = TenYearCHD))
p <- plot_grid(x, y)
title <- ggdraw() + draw_label("5. Relationship between TenYearCHD and Sex / Diabetes", fontface='bold')
plot_grid(title, p, ncol=1, rel_heights=c(0.1, 1))
model.matrix(~0+., data = df) %>%
cor(use="pairwise.complete.obs") %>%
corrplot(method = "color", type = "upper",number.cex = .5, order="hclust", addCoef.col = "black",tl.col = "#CC9900",            diag=F)
df_no_dummies = df[-c(1, 3, 4, 6, 7, 8, 9, 16)]
pairs.panels(df_no_dummies, gap=0, bg=c("blue","green")[df$TenYearCHD],pch=21)
set.seed(123)
split = createDataPartition(y = df$TenYearCHD, p= 0.8, list = F)
x_train = df[split,]
x_test = df[-split,]
dim(x_train)
dim(x_test)
table(x_train$TenYearCHD)
x_train = ovun.sample(TenYearCHD ~., data= x_train, method = "over", seed = 123)$data
table(x_train$TenYearCHD)
control <- trainControl(method="repeatedcv", number=10, repeats=3)
set.seed(123)
glm_clf <- train(TenYearCHD ~., data = x_train,
method = "glm",
tuneLength = 10,
trControl = control,
)
glm_clf
set.seed(123)
lda_clf = train(TenYearCHD ~., data = x_train, method="lda", trControl=control)
lda_clf
set.seed(7)
svm_clf = train(TenYearCHD ~., data = x_train, method = "svmLinear", trControl = control)
svm_clf
set.seed(123)
forest_clf = train(TenYearCHD ~., data = x_train, method = "rf",
trControl = control)
forest_clf
set.seed(123)
xgb_grid_1  <-  expand.grid(
nrounds = 50,
eta = c(0.03),
max_depth = 1,
gamma = 0,
colsample_bytree = 0.6,
min_child_weight = 1,
subsample = 0.5
)
xgb_clf = train(TenYearCHD ~., data = x_train,
method = "xgbTree",
tuneGrid=xgb_grid_1,
trControl = control
)
xgb_clf
set.seed(123)
knn_clf = train(TenYearCHD ~., data = x_train,
method = "knn",
tuneGrid = expand.grid(.k = c(3:10)),
trControl = control,
)
knn_clf
results = resamples(list(LOGREG=glm_clf, LDA=lda_clf, SVM=svm_clf, KNN=knn_clf, RF=forest_clf, XGB = xgb_clf))
summary(results)
scales = list(x=list(relation="free"), y=list(relation="free"))
bwplot(results, scales=scales)
glm_predictions = predict(glm_clf, x_test)
lda_predictions = predict(lda_clf, x_test)
svm_predictions = predict(svm_clf, x_test)
knn_predictions = predict(knn_clf, x_test)
forest_predictions = predict(forest_clf, x_test)
xgb_predictions = predict(xgb_clf, x_test)
glm_scores = predict(glm_clf, x_test, type = "prob")
lda_scores = predict(lda_clf, x_test, type = "prob")
#svm_scores = predict(svm_clf, x_test, type = "prob")
knn_scores = predict(knn_clf, x_test, type = "prob")
forest_scores = predict(forest_clf, x_test, type = "prob")
xgb_scores = predict(xgb_clf, x_test, type = "prob")
cm_glm = confusionMatrix(data = glm_predictions, reference = x_test$TenYearCHD, positive = "1")
cm_glm
pred_roc_glm = prediction(glm_scores[,2], x_test$TenYearCHD)
glm_ROCR = performance(pred_roc_glm, measure = "tpr", x.measure = "fpr")
par(mfrow=c(1,1))
plot(glm_ROCR, main = "ROC curve for Logistic Reg.", colorize = T, xlab="False Positive rate", ylab="True Positive rate" )
abline(a = 0, b = 1)
auc_glm = performance(pred_roc_glm, measure = "auc")
auc_glm = auc_glm@y.values[[1]]
auc_glm
cm_lda = confusionMatrix(data = lda_predictions, reference = x_test$TenYearCHD, positive = "1")
cm_lda
pred_roc_lda = prediction(lda_scores[,2], x_test$TenYearCHD)
lda_ROCR = performance(pred_roc_lda, measure = "tpr", x.measure = "fpr")
par(mfrow=c(1,1))
plot(lda_ROCR, main = "ROC curve for LDA", colorize = T, xlab="False Positive rate", ylab="True Positive rate" )
abline(a = 0, b = 1)
auc_lda = performance(pred_roc_lda, measure = "auc")
auc_lda = auc_lda@y.values[[1]]
auc_lda
cm_svm = confusionMatrix(data = svm_predictions, reference = x_test$TenYearCHD, positive = "1")
cm_svm
cm_knn = confusionMatrix(data = knn_predictions, reference = x_test$TenYearCHD, positive = "1")
cm_knn
pred_roc_knn = prediction(knn_scores[,2], x_test$TenYearCHD)
knn_ROCR = performance(pred_roc_knn, measure = "tpr", x.measure = "fpr")
par(mfrow=c(1,1))
plot(knn_ROCR, main = "ROC curve for KNN", colorize = T, xlab="False Positive rate", ylab="True Positive rate" )
abline(a = 0, b = 1)
auc_knn = performance(pred_roc_knn, measure = "auc")
auc_knn = auc_knn@y.values[[1]]
auc_knn
cm_forest = confusionMatrix(data = forest_predictions, reference = x_test$TenYearCHD, positive = "1")
cm_forest
pred_roc_forest = prediction(forest_scores[,2], x_test$TenYearCHD)
forest_ROCR = performance(pred_roc_forest, measure = "tpr", x.measure = "fpr")
par(mfrow=c(1,1))
plot(forest_ROCR, main = "ROC curve for Random forest", colorize = T, xlab="False Positive rate", ylab="True Positive rate" )
abline(a = 0, b = 1)
auc_forest = performance(pred_roc_forest, measure = "auc")
auc_forest = auc_forest@y.values[[1]]
auc_forest
cm_xgb = confusionMatrix(data = xgb_predictions, reference = x_test$TenYearCHD, positive = "1")
cm_xgb
pred_roc_xgb = prediction(xgb_scores[,2], x_test$TenYearCHD)
xgb_ROCR = performance(pred_roc_xgb, measure = "tpr", x.measure = "fpr")
par(mfrow=c(1,1))
plot(xgb_ROCR, main = "ROC curve for XGB", colorize = T, xlab="False Positive rate", ylab="True Positive rate" )
abline(a = 0, b = 1)
auc_xgb = performance(pred_roc_xgb, measure = "auc")
auc_xgb = auc_xgb@y.values[[1]]
auc_xgb
ModelType = c( "LOGREG", "LDA", "SVM", "KNN", "Random forest", "XGB")
TrainAcc = c(max(glm_clf$results$Accuracy), max(lda_clf$results$Accuracy),
max(svm_clf$results$Accuracy), max(knn_clf$results$Accuracy),
max(forest_clf$results$Accuracy),
max(xgb_clf$results$Accuracy))
Train_misscl_Er = 1 - TrainAcc
ValidAcc = c(cm_glm$overall[1], cm_lda$overall[1], cm_svm$overall[1],
cm_knn$overall[1], cm_forest$overall[1],
cm_xgb$overall[1])
Valid_misscl_Er = 1 - ValidAcc
auc_svm = NA
auc_scores = c(auc_glm, auc_lda, auc_svm, auc_knn, auc_forest, auc_xgb)
metrics = cbind(ModelType, TrainAcc, Train_misscl_Er, ValidAcc,
Valid_misscl_Er, auc_scores)
metrics = data.frame(metrics)
knitr::kable(metrics, digits = 3)
model_compare = cbind(Model=ModelType, Accuracy=TrainAcc)
model_compare = data.frame(model_compare)
ggplot(aes(x=Model, y=Accuracy), data=model_compare) +
geom_bar(stat='identity', fill = 'blue') +
ggtitle('Comparative Accuracy of Models on Cross-Validation Training Data') +
xlab('Models') +
ylab('Overall Accuracy')
model_compare = cbind(Model=ModelType, Accuracy=ValidAcc)
model_compare = data.frame(model_compare)
ggplot(aes(x=Model, y=Accuracy), data=model_compare) +
geom_bar(stat='identity', fill = 'orange') +
ggtitle('Comparative Accuracy of Models on Cross-Validation Test Data') +
xlab('Models') +
ylab('Overall Accuracy')
